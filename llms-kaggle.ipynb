{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9927549,"sourceType":"datasetVersion","datasetId":6102035},{"sourceId":10193065,"sourceType":"datasetVersion","datasetId":6297892},{"sourceId":10413146,"sourceType":"datasetVersion","datasetId":6435485}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:03.312202Z","iopub.execute_input":"2025-02-23T16:59:03.312856Z","iopub.status.idle":"2025-02-23T16:59:03.332890Z","shell.execute_reply.started":"2025-02-23T16:59:03.312798Z","shell.execute_reply":"2025-02-23T16:59:03.331509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:03.335392Z","iopub.execute_input":"2025-02-23T16:59:03.335936Z","iopub.status.idle":"2025-02-23T16:59:16.869176Z","shell.execute_reply.started":"2025-02-23T16:59:03.335883Z","shell.execute_reply":"2025-02-23T16:59:16.867123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:16.871663Z","iopub.execute_input":"2025-02-23T16:59:16.872213Z","iopub.status.idle":"2025-02-23T16:59:28.184716Z","shell.execute_reply.started":"2025-02-23T16:59:16.872152Z","shell.execute_reply":"2025-02-23T16:59:28.183112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install langchain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:28.187618Z","iopub.execute_input":"2025-02-23T16:59:28.188135Z","iopub.status.idle":"2025-02-23T16:59:43.571964Z","shell.execute_reply.started":"2025-02-23T16:59:28.188085Z","shell.execute_reply":"2025-02-23T16:59:43.569942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub.hf_api import HfFolder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:43.574310Z","iopub.execute_input":"2025-02-23T16:59:43.574898Z","iopub.status.idle":"2025-02-23T16:59:44.144685Z","shell.execute_reply.started":"2025-02-23T16:59:43.574849Z","shell.execute_reply":"2025-02-23T16:59:44.143189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"HfFolder.save_token('hf_****')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:44.146511Z","iopub.execute_input":"2025-02-23T16:59:44.146970Z","iopub.status.idle":"2025-02-23T16:59:44.153835Z","shell.execute_reply.started":"2025-02-23T16:59:44.146930Z","shell.execute_reply":"2025-02-23T16:59:44.152491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:44.155723Z","iopub.execute_input":"2025-02-23T16:59:44.156423Z","iopub.status.idle":"2025-02-23T16:59:48.349738Z","shell.execute_reply.started":"2025-02-23T16:59:44.156271Z","shell.execute_reply":"2025-02-23T16:59:48.348323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.351434Z","iopub.execute_input":"2025-02-23T16:59:48.351963Z","iopub.status.idle":"2025-02-23T16:59:48.356939Z","shell.execute_reply.started":"2025-02-23T16:59:48.351925Z","shell.execute_reply":"2025-02-23T16:59:48.355845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import cuda, bfloat16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.358447Z","iopub.execute_input":"2025-02-23T16:59:48.358761Z","iopub.status.idle":"2025-02-23T16:59:48.371890Z","shell.execute_reply.started":"2025-02-23T16:59:48.358733Z","shell.execute_reply":"2025-02-23T16:59:48.370737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.375616Z","iopub.execute_input":"2025-02-23T16:59:48.376030Z","iopub.status.idle":"2025-02-23T16:59:48.384884Z","shell.execute_reply.started":"2025-02-23T16:59:48.375995Z","shell.execute_reply":"2025-02-23T16:59:48.383795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.386231Z","iopub.execute_input":"2025-02-23T16:59:48.387285Z","iopub.status.idle":"2025-02-23T16:59:48.402790Z","shell.execute_reply.started":"2025-02-23T16:59:48.387244Z","shell.execute_reply":"2025-02-23T16:59:48.401543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom huggingface_hub import login\nlogin(token = 'hf_******')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.404156Z","iopub.execute_input":"2025-02-23T16:59:48.404554Z","iopub.status.idle":"2025-02-23T16:59:48.559010Z","shell.execute_reply.started":"2025-02-23T16:59:48.404494Z","shell.execute_reply":"2025-02-23T16:59:48.557832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !!! Need to accept conditions in hugging face\n# import torch\n# from transformers import pipeline\n\n# model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n# pipe = pipeline(\n#     \"text-generation\",\n#     model=model_id,\n#     torch_dtype=torch.bfloat16,\n#     device_map=\"auto\",\n# )\n# messages = [\n#     {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n# ]\n# outputs = pipe(\n#     messages,\n#     max_new_tokens=256,\n# )\n# print(outputs[0][\"generated_text\"][-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.560690Z","iopub.execute_input":"2025-02-23T16:59:48.561223Z","iopub.status.idle":"2025-02-23T16:59:48.566791Z","shell.execute_reply.started":"2025-02-23T16:59:48.561148Z","shell.execute_reply":"2025-02-23T16:59:48.565715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install einops flash_attn mamba_ssm causal_conv1d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:48.568259Z","iopub.execute_input":"2025-02-23T16:59:48.568753Z","iopub.status.idle":"2025-02-23T16:59:58.003331Z","shell.execute_reply.started":"2025-02-23T16:59:48.568707Z","shell.execute_reply":"2025-02-23T16:59:58.001417Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pure LLM's","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"infly/OpenCoder-8B-Instruct\"\n# infly/OpenCoder-8B-Instruct\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n                                             torch_dtype=torch.bfloat16,\n                                             device_map=\"auto\",\n                                             trust_remote_code=True)\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\nmessages=[\n    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n]\n\ninputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n\noutputs = model.generate(inputs, max_new_tokens=512, do_sample=False)\n\nresult = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.617167Z","iopub.status.idle":"2025-01-09T12:07:44.617510Z","shell.execute_reply.started":"2025-01-09T12:07:44.617344Z","shell.execute_reply":"2025-01-09T12:07:44.617362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"messages=[\n    { 'role': 'user', 'content': \"Give a small summary of Ripollet, a town in Spain close to Barcelona.\"}\n]\n\ninputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n\noutputs = model.generate(inputs, max_new_tokens=512, do_sample=False)\n\nresult = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.618805Z","iopub.status.idle":"2025-01-09T12:07:44.619208Z","shell.execute_reply.started":"2025-01-09T12:07:44.618987Z","shell.execute_reply":"2025-01-09T12:07:44.619009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def message_user_input(message_user='hello'):\n    messages=[\n        { 'role': 'user', 'content': message_user}\n    ]\n    \n    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n    \n    outputs = model.generate(inputs, max_new_tokens=512, do_sample=False)\n    \n    result = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n    return(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.620520Z","iopub.status.idle":"2025-01-09T12:07:44.620862Z","shell.execute_reply.started":"2025-01-09T12:07:44.620693Z","shell.execute_reply":"2025-01-09T12:07:44.620712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"message_user_input(message_user='em pots parlar en català?')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.621862Z","iopub.status.idle":"2025-01-09T12:07:44.622249Z","shell.execute_reply.started":"2025-01-09T12:07:44.622042Z","shell.execute_reply":"2025-01-09T12:07:44.622088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response_llm=message_user_input(message_user='em pots parlar en català?')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.624188Z","iopub.status.idle":"2025-01-09T12:07:44.624580Z","shell.execute_reply.started":"2025-01-09T12:07:44.624403Z","shell.execute_reply":"2025-01-09T12:07:44.624423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"initial_message=\"How can I create a videogame for children between age 5 and 10 so they can learn maths with fun?\"\nresponse_llm=message_user_input(message_user=initial_message)\nprint(response_llm)\nfor _ in range(4):\n\n    response_llm=message_user_input(message_user=response_llm)\n    print(response_llm)\n    print('%%%%%%%%%%%%%%%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.626016Z","iopub.status.idle":"2025-01-09T12:07:44.626418Z","shell.execute_reply.started":"2025-01-09T12:07:44.626236Z","shell.execute_reply":"2025-01-09T12:07:44.626265Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating a loop","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Crew AI with HuggingFace\n\nFrom training:\n\ncrewai==0.28.8 -> it is giving errors, better with 0.86.0 <br>\ncrewai_tools==0.1.6 -> using 0.17.0<br>\nlangchain_community==0.0.29 -> using 0.3.13 <br>","metadata":{}},{"cell_type":"code","source":"pip install crewai==0.86.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T16:59:58.005830Z","iopub.execute_input":"2025-02-23T16:59:58.006588Z","iopub.status.idle":"2025-02-23T17:02:34.063831Z","shell.execute_reply.started":"2025-02-23T16:59:58.006531Z","shell.execute_reply":"2025-02-23T17:02:34.062158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install crewai_tools==0.17.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:02:34.066361Z","iopub.execute_input":"2025-02-23T17:02:34.066994Z","iopub.status.idle":"2025-02-23T17:02:52.326304Z","shell.execute_reply.started":"2025-02-23T17:02:34.066936Z","shell.execute_reply":"2025-02-23T17:02:52.324778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install langchain_community==0.3.13","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:02:52.328132Z","iopub.execute_input":"2025-02-23T17:02:52.328536Z","iopub.status.idle":"2025-02-23T17:03:07.179421Z","shell.execute_reply.started":"2025-02-23T17:02:52.328500Z","shell.execute_reply":"2025-02-23T17:03:07.177846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Warning control\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load environment variables\n\n\nimport os\nimport yaml\nfrom crewai import Agent, Task, Crew, LLM\nfrom crewai_tools import SerperDevTool, \\\n                         ScrapeWebsiteTool, \\\n                         WebsiteSearchTool","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:03:07.181646Z","iopub.execute_input":"2025-02-23T17:03:07.182154Z","iopub.status.idle":"2025-02-23T17:03:17.976042Z","shell.execute_reply.started":"2025-02-23T17:03:07.182112Z","shell.execute_reply":"2025-02-23T17:03:17.974876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Warning control\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:03:17.977465Z","iopub.execute_input":"2025-02-23T17:03:17.978493Z","iopub.status.idle":"2025-02-23T17:03:17.983989Z","shell.execute_reply.started":"2025-02-23T17:03:17.978450Z","shell.execute_reply":"2025-02-23T17:03:17.982801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ[\"HUGGINGFACE_API_KEY\"]=\"hf_******\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:03:17.985250Z","iopub.execute_input":"2025-02-23T17:03:17.985718Z","iopub.status.idle":"2025-02-23T17:03:18.003952Z","shell.execute_reply.started":"2025-02-23T17:03:17.985669Z","shell.execute_reply":"2025-02-23T17:03:18.002625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check if I can run DeepSeek\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pip install vllm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:09:33.988549Z","iopub.execute_input":"2025-02-23T17:09:33.989093Z","iopub.status.idle":"2025-02-23T17:13:59.956959Z","shell.execute_reply.started":"2025-02-23T17:09:33.989034Z","shell.execute_reply":"2025-02-23T17:13:59.954351Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# vllm serve \"deepseek-ai/DeepSeek-R1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:13:59.961748Z","iopub.execute_input":"2025-02-23T17:13:59.962430Z","iopub.status.idle":"2025-02-23T17:13:59.976583Z","shell.execute_reply.started":"2025-02-23T17:13:59.962382Z","shell.execute_reply":"2025-02-23T17:13:59.974500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This one works for version CrewAI 0.86.0\nfrom crewai import Agent, LLM\nllm=LLM(api_key=os.getenv(\"HUGGINGFACE_API_KEY\"),model= \"huggingface/HuggingFaceH4/zephyr-7b-beta\", max_tokens=6000)\n#Models used:\n#huggingface/HuggingFaceH4/zephyr-7b-beta -> this one works\n#huggingface/Qwen/QwQ-32B-Preview -> this one is not working\n#huggingface/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF -> NEED TO ACCEPT AGREEMENT\n#huggingface/tiiuae/Falcon3-10B-Instruct -> Not working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:10.837425Z","iopub.execute_input":"2025-02-23T17:15:10.838101Z","iopub.status.idle":"2025-02-23T17:15:10.846635Z","shell.execute_reply.started":"2025-02-23T17:15:10.838016Z","shell.execute_reply":"2025-02-23T17:15:10.844792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tried for version 0.28.0 but did not work\n#from langchain_community.llms import HuggingFaceHub\n\n#llm = HuggingFaceHub(\n #   repo_id=\"huggingface/HuggingFaceH4/zephyr-7b-beta\",\n  #  huggingfacehub_api_token=\"hf_*****\",\n   # task=\"text-generation\"\n#)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:14.316199Z","iopub.execute_input":"2025-02-23T17:15:14.316736Z","iopub.status.idle":"2025-02-23T17:15:14.322697Z","shell.execute_reply.started":"2025-02-23T17:15:14.316692Z","shell.execute_reply":"2025-02-23T17:15:14.321295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CREW AI : Article about a topic","metadata":{}},{"cell_type":"code","source":"scrape_tool = ScrapeWebsiteTool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:15.191554Z","iopub.execute_input":"2025-02-23T17:15:15.192121Z","iopub.status.idle":"2025-02-23T17:15:15.201044Z","shell.execute_reply.started":"2025-02-23T17:15:15.192046Z","shell.execute_reply":"2025-02-23T17:15:15.198986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"planner = Agent(\n    role=\"Content Planner\",\n    goal=\"Plan engaging and factually accurate content on {topic}\",\n    backstory=\"You're working on planning a blog article \"\n              \"about the topic: {topic}.\"\n              \"You collect information that helps the \"\n              \"audience learn something \"\n              \"and make informed decisions. \"\n              \"Your work is the basis for \"\n              \"the Content Writer to write an article on this topic.\",\n    allow_delegation=False,\n\tverbose=True,\n    tools = [scrape_tool],\n    llm=llm\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:15.587858Z","iopub.execute_input":"2025-02-23T17:15:15.588417Z","iopub.status.idle":"2025-02-23T17:15:15.602698Z","shell.execute_reply.started":"2025-02-23T17:15:15.588371Z","shell.execute_reply":"2025-02-23T17:15:15.600920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"writer = Agent(\n    role=\"Content Writer\",\n    goal=\"Write insightful and factually accurate \"\n         \"opinion piece about the topic: {topic}\",\n    backstory=\"You're working on a writing \"\n              \"a new opinion piece about the topic: {topic}. \"\n              \"You base your writing on the work of \"\n              \"the Content Planner, who provides an outline \"\n              \"and relevant context about the topic. \"\n              \"You follow the main objectives and \"\n              \"direction of the outline, \"\n              \"as provide by the Content Planner. \"\n              \"You also provide objective and impartial insights \"\n              \"and back them up with information \"\n              \"provide by the Content Planner. \"\n              \"You acknowledge in your opinion piece \"\n              \"when your statements are opinions \"\n              \"as opposed to objective statements.\",\n    allow_delegation=False,\n    verbose=True,\n    llm=llm\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:16.109994Z","iopub.execute_input":"2025-02-23T17:15:16.110562Z","iopub.status.idle":"2025-02-23T17:15:16.120699Z","shell.execute_reply.started":"2025-02-23T17:15:16.110518Z","shell.execute_reply":"2025-02-23T17:15:16.119235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"editor = Agent(\n    role=\"Editor\",\n    goal=\"Edit a given blog post to align with \"\n         \"the writing style of the organization. \",\n    backstory=\"You are an editor who receives a blog post \"\n              \"from the Content Writer. \"\n              \"Your goal is to review the blog post \"\n              \"to ensure that it follows journalistic best practices,\"\n              \"provides balanced viewpoints \"\n              \"when providing opinions or assertions, \"\n              \"and also avoids major controversial topics \"\n              \"or opinions when possible.\",\n    allow_delegation=False,\n    verbose=True,\n    llm=llm\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:18.324610Z","iopub.execute_input":"2025-02-23T17:15:18.325141Z","iopub.status.idle":"2025-02-23T17:15:18.335396Z","shell.execute_reply.started":"2025-02-23T17:15:18.325101Z","shell.execute_reply":"2025-02-23T17:15:18.333961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plan = Task(\n    description=(\n        \"1. Prioritize the latest trends, key players, \"\n            \"and noteworthy news on {topic}.\\n\"\n        \"2. Identify the target audience, considering \"\n            \"their interests and pain points.\\n\"\n        \"3. Develop a detailed content outline including \"\n            \"an introduction, key points, and a call to action.\\n\"\n        \"4. Include SEO keywords and relevant data or sources.\"\n    ),\n    expected_output=\"A comprehensive content plan document \"\n        \"with an outline, audience analysis, \"\n        \"SEO keywords, and resources.\",\n    agent=planner\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:20.999033Z","iopub.execute_input":"2025-02-23T17:15:20.999795Z","iopub.status.idle":"2025-02-23T17:15:21.012297Z","shell.execute_reply.started":"2025-02-23T17:15:20.999724Z","shell.execute_reply":"2025-02-23T17:15:21.010776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"write = Task(\n    description=(\n        \"1. Use the content plan to craft a compelling \"\n            \"blog post on {topic}.\\n\"\n        \"2. Incorporate SEO keywords naturally.\\n\"\n\t\t\"3. Sections/Subtitles are properly named \"\n            \"in an engaging manner.\\n\"\n        \"4. Ensure the post is structured with an \"\n            \"engaging introduction, insightful body, \"\n            \"and a summarizing conclusion.\\n\"\n        \"5. Proofread for grammatical errors and \"\n            \"alignment with the brand's voice.\\n\"\n    ),\n    expected_output=\"A well-written blog post \"\n        \"in markdown format, ready for publication, \"\n        \"each section should have 2 or 3 paragraphs.\",\n    agent=writer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:21.358804Z","iopub.execute_input":"2025-02-23T17:15:21.359471Z","iopub.status.idle":"2025-02-23T17:15:21.368708Z","shell.execute_reply.started":"2025-02-23T17:15:21.359412Z","shell.execute_reply":"2025-02-23T17:15:21.367171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"edit = Task(\n    description=(\"Proofread the given blog post for \"\n                 \"grammatical errors and \"\n                 \"alignment with the brand's voice.\"),\n    expected_output=\"A well-written blog post in markdown format, \"\n                    \"ready for publication, \"\n                    \"each section should have 2 or 3 paragraphs.\",\n    agent=editor\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:24.004668Z","iopub.execute_input":"2025-02-23T17:15:24.005216Z","iopub.status.idle":"2025-02-23T17:15:24.014744Z","shell.execute_reply.started":"2025-02-23T17:15:24.005171Z","shell.execute_reply":"2025-02-23T17:15:24.013025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"crew = Crew(\n    agents=[planner, writer, editor],\n    tasks=[plan, write, edit],\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:24.354682Z","iopub.execute_input":"2025-02-23T17:15:24.355868Z","iopub.status.idle":"2025-02-23T17:15:24.374301Z","shell.execute_reply.started":"2025-02-23T17:15:24.355803Z","shell.execute_reply":"2025-02-23T17:15:24.372392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = crew.kickoff(inputs={\"topic\": \"Future of concrete\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:15:24.759843Z","iopub.execute_input":"2025-02-23T17:15:24.760368Z","iopub.status.idle":"2025-02-23T17:19:01.843350Z","shell.execute_reply.started":"2025-02-23T17:15:24.760323Z","shell.execute_reply":"2025-02-23T17:19:01.840218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking outputs\n#print(f\"Raw Output: {result.raw}\")\n#if result.json_dict:\n #   print(f\"JSON Output: {json.dumps(result.json_dict, indent=2)}\")\n#if result.pydantic:\n   # print(f\"Pydantic Output: {result.pydantic}\")\n#print(f\"Tasks Output: {result.tasks_output}\")\n#print(f\"Token Usage: {result.token_usage}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.659094Z","iopub.status.idle":"2025-01-09T12:07:44.659518Z","shell.execute_reply.started":"2025-01-09T12:07:44.659287Z","shell.execute_reply":"2025-01-09T12:07:44.659311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Markdown\nMarkdown(result.tasks_output[-1].raw)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:19:01.845346Z","iopub.status.idle":"2025-02-23T17:19:01.845823Z","shell.execute_reply.started":"2025-02-23T17:19:01.845632Z","shell.execute_reply":"2025-02-23T17:19:01.845654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Token Usage: {result.token_usage}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T17:19:01.847642Z","iopub.status.idle":"2025-02-23T17:19:01.848156Z","shell.execute_reply.started":"2025-02-23T17:19:01.847910Z","shell.execute_reply":"2025-02-23T17:19:01.847932Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### This is used to check token creation for a specific model","metadata":{}},{"cell_type":"code","source":"# import torch\n# from transformers import AutoTokenizer, AutoModelForCausalLM\n# from huggingface_hub import InferenceClient\n# client=InferenceClient(api_key=\"hf_****\")\n\n# model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n# # infly/OpenCoder-8B-Instruct\n\n# messages=[\n#     { 'role': 'user', 'content': \"what is the maximum number of tokens that you accept.\"}\n# ]\n\n# completion=client.chat.completions.create(model=model_name,\n#                                           messages=messages,\n#                                           max_tokens=500\n#                                          )\n# print(completion.choices[0].message)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.664356Z","iopub.status.idle":"2025-01-09T12:07:44.664709Z","shell.execute_reply.started":"2025-01-09T12:07:44.664535Z","shell.execute_reply":"2025-01-09T12:07:44.664554Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Crew AI: Stock analysis","metadata":{}},{"cell_type":"code","source":"from crewai_tools import ScrapeWebsiteTool, SerperDevTool, FileReadTool\nfrom crewai import Crew, Process\n\n# search_tool = SerperDevTool() -> need tokens to connect to API\nscrape_tool = ScrapeWebsiteTool()\n# scrape_tool2 = ScrapeWebsiteTool(\n#     website_url=\"https://www.expansion.com/mercados/cotizaciones/indices/ibex35_I.IB.html\"\n# )\n\nfilereadtool=FileReadTool()\n\n# Agents definitions\ndata_analyst_agent = Agent(\n    role=\"Data Analyst\",\n    goal=\"Check financial information of the company\",\n    backstory=\"Specializing in financial markets, this agent \"\n              \"provides crucial insights. With a knack for data, \"\n              \"the Data Analyst Agent is the cornerstone for \"\n              \"informing trading decisions. It has a lot of \"\n              \" knowledge about Spanish stock exchange, IBEX 35. \"\n    \"If you have errors to find the information, do not worry, you can search in https://www.expansion.com/\"\n    \"Do not worry if you do not have all information, finish the task as soon as possible\",\n    verbose=True,\n    allow_delegation=True,\n    tools = [scrape_tool], \n    llm=llm\n)\n\n# Agents definitions\ndata_analyst_agent_2 = Agent(\n    role=\"Data Analyst\",\n    goal=\"Check news that could impact the company\",\n    backstory=\"This agent is able to correlate events with price movements in stocks \"\n    \"If you have errors to find the information, do not worry, you can search in https://www.lavanguardia.com/ or https://www.expansion.com/ \"\n    \"Do not worry if you do not have all information, finish the task as soon as possible\",\n    verbose=True,\n    allow_delegation=True,\n    tools = [scrape_tool], \n    llm=llm\n)\n\nexecution_agent = Agent(\n    role=\"Trade Advisor\",\n    goal=\"Suggest optimal trade execution strategies \"\n         \"based on approved trading strategies. It also follows the news and other world events \"\n         \"information to provide ideas about the evolution of the stock price. \"\n    \"It also considers the dividends that the company pays. \",\n    backstory=\"This agent specializes in analyzing the timing, price, \"\n              \"and logistical details of potential trades. By evaluating \"\n              \"these factors, it provides well-founded suggestions for \"\n              \"when and how trades should be executed to maximize \"\n              \"efficiency and adherence to strategy.\",\n    verbose=True,\n    allow_delegation=True,\n    tools = [scrape_tool],\n    llm=llm\n)\n\n# trading_strategy_agent = Agent(\n#     role=\"Trading Strategy Developer\",\n#     goal=\"Develop and test various trading strategies based \"\n#          \"on insights from the Data Analyst Agent.\",\n#     backstory=\"Equipped with a deep understanding of financial \"\n#               \"markets and quantitative analysis, this agent \"\n#               \"devises and refines trading strategies. It evaluates \"\n#               \"the performance of different approaches to determine \"\n#               \"the most profitable and risk-averse options.\",\n#     verbose=True,\n#     allow_delegation=True,\n#     # tools = [scrape_tool],\n#     llm=llm\n# )\n\nrisk_management_agent = Agent(\n    role=\"Risk Advisor\",\n    goal=\"Evaluate and provide insights on the risks \"\n         \"associated with potential trading activities.\",\n    backstory=\"Armed with a deep understanding of risk assessment models \"\n              \"and market dynamics, this agent scrutinizes the potential \"\n              \"risks of proposed trades. It offers a detailed analysis of \"\n              \"risk exposure and suggests safeguards to ensure that \"\n              \"trading activities align with the firm’s risk tolerance.\"\n    \" The agent has an invesment horizon of 1 to 3 months.\"\n    ,\n    verbose=True,\n    allow_delegation=True,\n    tools = [scrape_tool],\n    llm=llm\n)\n\n\n# Task for Data Analyst Agent: Analyze Market Data\ndata_analysis_task = Task(\n    description=(\n        \"Find the financial information about \"\n        \"the selected stock ({stock_selection}) that could impact the stock price. \"\n        \"Summarize this information for a clear view of future performance.\"\n        \"You have to include information like dividend, dividend yield, revenue, profits, costs, etc.\"\n    ),\n    expected_output=(\n        \"Insights and alerts about significant market \"\n        \"opportunities or threats for {stock_selection}.\"\n       \n    ),\n    agent=data_analyst_agent,\n)\ndata_analysis_task_2 = Task(\n    description=(\n        \"Find information about \"\n        \"news that could impact the stock price. You have to correlate them with the sector of the company {stock_selection} \"\n        \"You have to include all current events that could impact the stock price (wars, catastrophes, terrorist attacks, economic information of Spain).\"\n        \"Group them in positive or negative impact for the stock.\"\n        \n    ),\n    expected_output=(\n        \"Insights and alerts about significant market \"\n        \"opportunities or threats for {stock_selection}.\"\n        \"The information could be extracted from El Economista, Expansión or Cinco Días web pages.\"\n    ),\n    agent=data_analyst_agent_2,\n)\n\n# Task for Trade Advisor Agent: Plan Trade Execution\nexecution_planning_task = Task(\n    description=(\n        \"Using all information provided, you have to decide if we can buy that stock or not.\"\n        \"The trading strategy will be: {trading_strategy_preference}\"\n    ),\n    expected_output=(\n        \"Detailed execution plans suggesting how and when to \"\n        \"execute trades for {stock_selection} with the amount of {initial_capital}.\"\n    ),\n    agent=execution_agent,\n)\n# Task for Trading Strategy Agent: Develop Trading Strategies\n# strategy_development_task = Task(\n#     description=(\n#         \"Develop and refine trading strategies based on \"\n#         \"the insights from the Data Analyst and \"\n#         \"user-defined risk tolerance ({risk_tolerance}). \"\n#         \"Consider trading preferences ({trading_strategy_preference}).\"\n#     ),\n#     expected_output=(\n#         \"A set of potential trading strategies for {stock_selection} \"\n#         \"that align with the user's risk tolerance.\"\n#     ),\n#     agent=trading_strategy_agent,\n# )\n\n# Task for Risk Advisor Agent: Assess Trading Risks\nrisk_assessment_task = Task(\n    description=(\n        \"Evaluate the risks associated with the proposed trading \"\n        \"strategies and execution plans for {stock_selection}. \"\n        \"Provide a detailed analysis of potential risks \"\n        \"and suggest mitigation strategies.\"\n        \"The risk tolerance of the user is: {risk_tolerance}\"\n    ),\n    expected_output=(\n        \"A comprehensive risk analysis report detailing potential \"\n        \"risks and mitigation recommendations for {stock_selection}.\"\n    ),\n    agent=risk_management_agent,\n)\n\n\nfrom crewai import Crew, Process\n# from langchain_openai import ChatOpenAI\n\n# Define the crew with agents and tasks\nfinancial_trading_crew = Crew(\n    agents=[data_analyst_agent_2,\n        data_analyst_agent, \n            \n            # trading_strategy_agent, \n            execution_agent,\n            risk_management_agent],\n    \n    tasks=[data_analysis_task_2,\n        data_analysis_task, \n           \n           # strategy_development_task, \n        execution_planning_task,\n           risk_assessment_task],\n    \n    manager_llm=llm,\n    # process=Process.hierarchical,\n    verbose=True\n)\n\n# Example data for kicking off the process\nfinancial_trading_inputs = {\n    'stock_selection': 'International Airlines Group . Yahoo finance ticker is: IAG.MC',\n    'initial_capital': '1000',\n    'risk_tolerance': 'Medium',\n    'trading_strategy_preference': 'Month Trading',\n    'news_impact_consideration': True\n}\n\n### this execution will take some time to run\nresult = financial_trading_crew.kickoff(inputs=financial_trading_inputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T18:13:37.143485Z","iopub.execute_input":"2025-02-23T18:13:37.144268Z","iopub.status.idle":"2025-02-23T18:16:41.251572Z","shell.execute_reply.started":"2025-02-23T18:13:37.144218Z","shell.execute_reply":"2025-02-23T18:16:41.248690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.667936Z","iopub.status.idle":"2025-01-09T12:07:44.668342Z","shell.execute_reply.started":"2025-01-09T12:07:44.668147Z","shell.execute_reply":"2025-01-09T12:07:44.668166Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Crew AI: Financial analysis 2\n\nhttps://learn.deeplearning.ai/courses/multi-ai-agent-systems-with-crewai/lesson/6/multi-agent-customer-support-automation-(code)","metadata":{}},{"cell_type":"code","source":"pip install spider-client 'crewai[tools]'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T15:27:30.678381Z","iopub.execute_input":"2025-01-09T15:27:30.678776Z","iopub.status.idle":"2025-01-09T15:27:47.039927Z","shell.execute_reply.started":"2025-01-09T15:27:30.678743Z","shell.execute_reply":"2025-01-09T15:27:47.038586Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I need an API\nfrom crewai_tools import SpiderTool\n# spider_tool = SpiderTool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T14:19:25.996825Z","iopub.execute_input":"2025-01-09T14:19:25.997241Z","iopub.status.idle":"2025-01-09T14:19:26.003253Z","shell.execute_reply.started":"2025-01-09T14:19:25.997201Z","shell.execute_reply":"2025-01-09T14:19:26.001644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from crewai_tools import SeleniumScrapingTool","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T14:11:46.567943Z","iopub.status.idle":"2025-01-09T14:11:46.568355Z","shell.execute_reply.started":"2025-01-09T14:11:46.568161Z","shell.execute_reply":"2025-01-09T14:11:46.568180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Not a good tool to process tables -> for large tables, I exceed the limit of tokens and get errors\nfrom crewai_tools import FileReadTool\n\n# Initialize the tool to read any files the agents knows or lean the path for\n# file_read_tool = FileReadTool()\nfilereadtool=FileReadTool(file_path=\"/kaggle/input/ibex-jumps-20y-stocks/sample2.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T14:19:30.557135Z","iopub.execute_input":"2025-01-09T14:19:30.557532Z","iopub.status.idle":"2025-01-09T14:19:30.563273Z","shell.execute_reply.started":"2025-01-09T14:19:30.557495Z","shell.execute_reply":"2025-01-09T14:19:30.562079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from crewai_tools import FileWriterTool\n\n# Initialize the tool\nfile_writer_tool = FileWriterTool()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T15:27:47.041468Z","iopub.execute_input":"2025-01-09T15:27:47.042000Z","iopub.status.idle":"2025-01-09T15:27:47.047684Z","shell.execute_reply.started":"2025-01-09T15:27:47.041964Z","shell.execute_reply":"2025-01-09T15:27:47.046659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from crewai_tools import ScrapeWebsiteTool, SerperDevTool, FileReadTool\nfrom crewai import Crew, Process\n\n# search_tool = SerperDevTool() -> need tokens to connect to API\nscrape_tool = ScrapeWebsiteTool()\n\n\n# filereadtool=FileReadTool(file_path=\"/kaggle/input/ibex-jumps-20y-stocks/sample2.csv\") # takes a lot of time,\n# it does not process very well excel and tables and it does not generate interesting outputs\n\n# Agents definitions\ndata_analyst_agent = Agent(\n    role=\"Data Analyst\",\n    goal=\"Identify patterns in financial assets \"\n         \"to identify trends and predict market movements. \"\n    \"Also compare with other stocks and compare with future commodities if necessary.\",\n    backstory=\"Specializing in financial markets, this agent \"\n              \"uses statistical modeling and machine learning \"\n              \"to provide crucial insights. With a knack for data, \"\n              \"the Data Analyst Agent is the cornerstone for \"\n              \"informing trading decisions. It has a lot of \"\n              \" knowledge about Spanish stock exchange, IBEX 35\",\n    verbose=True,\n    allow_delegation=True,\n    tools = [scrape_tool], \n    llm=llm\n)\n\nreporter_agent = Agent(\n    role=\"Reporter agent of financial information\",\n    goal=\"Write all the information of the data analyst in a structured manner\",\n    backstory=\"Specializing in financial markets, this agent \"\n              \"structures all financial information to be used by decision makers.\"\n    \" Also has experience in the Spanish stock exchange.\",\n    verbose=True,\n    allow_delegation=True,\n    tools = [file_writer_tool], \n    llm=llm\n)\n\n# Task for Data Analyst Agent: Analyze Market Data\ndata_analysis_task = Task(\n    description=(\n        \"Continuously monitor and analyze market data for \"\n        \"the selected company {company_selected} (yahoo finance ticker: {stock_selection}). \"\n        \"Use statistical modeling and machine learning to \"\n        \"identify trends and predict market movements. \"\n        \" Your objective is the following: ({objective_agent_solve})\"\n        \"When you finish, create a pdf to report all your findings.\"\n    ),\n    expected_output=(\n        \"Insights and alerts about significant market \"\n        \"opportunities or threats for {stock_selection}.\"\n    ),\n    agent=data_analyst_agent,\n)\n\nreporting_task = Task(\n    description=(\n        \"Provide a clear view of data analyst findings.\"\n        \n    ),\n    expected_output=(\n        \"Clear information of {stock_selection} obtained from data analyst.\"\n    ),\n    agent=reporter_agent,\n)\n\nfrom crewai import Crew, Process\n# from langchain_openai import ChatOpenAI\n\n# Define the crew with agents and tasks\nfinancial_trading_crew = Crew(\n    agents=[data_analyst_agent, reporter_agent],\n    \n    tasks=[data_analysis_task, reporting_task],\n    \n    # manager_llm=llm,\n    # process=Process.hierarchical,\n    verbose=True\n)\n\n# Example data for kicking off the process\nfinancial_trading_inputs = {\n    'company_selected':'Caixabank',\n    'stock_selection': 'CABK.MC',\n    'objective_agent_solve': ' I want to know the evolution of the stock in the next 2 days and compare with similar stocks'\n}\n\n### this execution will take some time to run\nresult = financial_trading_crew.kickoff(inputs=financial_trading_inputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T15:51:07.451251Z","iopub.execute_input":"2025-01-09T15:51:07.452189Z","iopub.status.idle":"2025-01-09T15:51:07.981236Z","shell.execute_reply.started":"2025-01-09T15:51:07.452145Z","shell.execute_reply":"2025-01-09T15:51:07.979754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T15:48:31.414438Z","iopub.status.idle":"2025-01-09T15:48:31.415023Z","shell.execute_reply.started":"2025-01-09T15:48:31.414739Z","shell.execute_reply":"2025-01-09T15:48:31.414768Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Crew AI -> Home prices: Better with OpenAI and other paying tools","metadata":{}},{"cell_type":"code","source":"tool_selenium = SeleniumScrapingTool(\n    website_url='https://www.idealista.com/',\n    css_element='campoBus'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.677802Z","iopub.status.idle":"2025-01-09T12:07:44.678223Z","shell.execute_reply.started":"2025-01-09T12:07:44.678002Z","shell.execute_reply":"2025-01-09T12:07:44.678021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"support_agent = Agent(\n    role=\"Senior Support Representative\",\n\tgoal=\"Be the most friendly and helpful \"\n        \"support representative in your team\",\n\tbackstory=(\n\t\t\"You work at Real Estate company and \"\n        \" are now working on providing \"\n\t\t\"support to {customer}, a super important customer \"\n        \" for your company.\"\n\t\t\"You need to make sure that you provide the best support!\"\n\t\t\"Make sure to provide full complete answers, \"\n        \" and make no assumptions.\"\n\t),\n\tallow_delegation=False,\n    llm=llm,\n\tverbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.679287Z","iopub.status.idle":"2025-01-09T12:07:44.679648Z","shell.execute_reply.started":"2025-01-09T12:07:44.679465Z","shell.execute_reply":"2025-01-09T12:07:44.679483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"support_quality_assurance_agent = Agent(\n\trole=\"Support Quality Assurance Specialist\",\n\tgoal=\"Get recognition for providing the \"\n    \"best support quality assurance in your team\",\n\tbackstory=(\n\t\t\"You work at Real Estate company and \"\n        \"are now working with your team \"\n\t\t\"on a request from {customer} ensuring that \"\n        \"the support representative is \"\n\t\t\"providing the best support possible.\\n\"\n\t\t\"You need to make sure that the support representative \"\n        \"is providing full\"\n\t\t\"complete answers, and make no assumptions.\"\n\t),\n\tverbose=True,\n    llm=llm\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.680822Z","iopub.status.idle":"2025-01-09T12:07:44.681250Z","shell.execute_reply.started":"2025-01-09T12:07:44.681019Z","shell.execute_reply":"2025-01-09T12:07:44.681039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs_scrape_tool = ScrapeWebsiteTool(\n    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n)\n\ninquiry_resolution = Task(\n    description=(\n        \"{customer} just reached out with a super important ask:\\n\"\n\t    \"{inquiry}\\n\\n\"\n        \"{person} from {customer} is the one that reached out. \"\n\t\t\"Make sure to use everything you know \"\n        \"to provide the best support possible.\"\n\t\t\"You must strive to provide a complete \"\n        \"and accurate response to the customer's inquiry.\"\n    ),\n    expected_output=(\n\t    \"A detailed, informative response to the \"\n        \"customer's inquiry that addresses \"\n        \"all aspects of their question.\\n\"\n        \"The response should include references \"\n        \"to everything you used to find the answer, \"\n        \"including external data or solutions. \"\n        \"Ensure the answer is complete, \"\n\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n\t\t\"tone throughout.\"\n    ),\n\ttools=[tool_selenium],\n    agent=support_agent\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.682472Z","iopub.status.idle":"2025-01-09T12:07:44.682821Z","shell.execute_reply.started":"2025-01-09T12:07:44.682650Z","shell.execute_reply":"2025-01-09T12:07:44.682669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quality_assurance_review = Task(\n    description=(\n        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n\t\t\"high-quality standards expected for customer support.\\n\"\n        \"Verify that all parts of the customer's inquiry \"\n        \"have been addressed \"\n\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n        \"Check for references and sources used to \"\n        \" find the information, \"\n\t\t\"ensuring the response is well-supported and \"\n        \"leaves no questions unanswered.\"\n    ),\n    expected_output=(\n        \"A final, detailed, and informative response \"\n        \"ready to be sent to the customer.\\n\"\n        \"This response should fully address the \"\n        \"customer's inquiry, incorporating all \"\n\t\t\"relevant feedback and improvements.\\n\"\n\t\t\"Don't be too formal, we are a chill and cool company \"\n\t    \"but maintain a professional and friendly tone throughout.\"\n    ),\n    agent=support_quality_assurance_agent\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.684344Z","iopub.status.idle":"2025-01-09T12:07:44.684714Z","shell.execute_reply.started":"2025-01-09T12:07:44.684536Z","shell.execute_reply":"2025-01-09T12:07:44.684556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"crew = Crew(\n  agents=[support_agent, support_quality_assurance_agent],\n  tasks=[inquiry_resolution, quality_assurance_review],\n  verbose=True,\n  memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.686009Z","iopub.status.idle":"2025-01-09T12:07:44.686401Z","shell.execute_reply.started":"2025-01-09T12:07:44.686228Z","shell.execute_reply":"2025-01-09T12:07:44.686246Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Crew AI with Open AI","metadata":{}},{"cell_type":"code","source":"files = {\n    'agents': '/kaggle/input/config-crewai/agents.yaml',\n    'tasks': '/kaggle/input/config-crewai/tasks.yaml'\n}\n\n# Load configurations from YAML files\nconfigs = {}\nfor config_type, file_path in files.items():\n    with open(file_path, 'r') as file:\n        configs[config_type] = yaml.safe_load(file)\n\n# Assign loaded configurations to specific variables\nagents_config = configs['agents']\ntasks_config = configs['tasks']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.688063Z","iopub.status.idle":"2025-01-09T12:07:44.688595Z","shell.execute_reply.started":"2025-01-09T12:07:44.688360Z","shell.execute_reply":"2025-01-09T12:07:44.688388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from typing import List\nfrom pydantic import BaseModel, Field\n\nclass TaskEstimate(BaseModel):\n    task_name: str = Field(..., description=\"Name of the task\")\n    estimated_time_hours: float = Field(..., description=\"Estimated time to complete the task in hours\")\n    required_resources: List[str] = Field(..., description=\"List of resources required to complete the task\")\n\nclass Milestone(BaseModel):\n    milestone_name: str = Field(..., description=\"Name of the milestone\")\n    tasks: List[str] = Field(..., description=\"List of task IDs associated with this milestone\")\n\nclass ProjectPlan(BaseModel):\n    tasks: List[TaskEstimate] = Field(..., description=\"List of tasks with their estimates\")\n    milestones: List[Milestone] = Field(..., description=\"List of project milestones\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.689768Z","iopub.status.idle":"2025-01-09T12:07:44.690169Z","shell.execute_reply.started":"2025-01-09T12:07:44.689959Z","shell.execute_reply":"2025-01-09T12:07:44.689979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"llm = LLM(\n    model=\"huggingface/infly/OpenCoder-8B-Instruct\",\n    base_url=\"https://huggingface.co/v1\",\n    api_key=\"hf_*****\"\n)\n\nimport os\nfrom litellm import completion\n\n# [OPTIONAL] set env var\nos.environ[\"HUGGINGFACE_API_KEY\"] = \"hf_*********\"\n\nmessages = [{ \"content\": \"There's a llama in my garden  What should I do?\",\"role\": \"user\"}]\n\n# e.g. Call 'https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct' from Serverless Inference API\nresponse = completion(\n    model=\"huggingface/infly/OpenCoder-8B-Instruct\",\n    messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}],\n    stream=True\n)\n\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.692245Z","iopub.status.idle":"2025-01-09T12:07:44.692638Z","shell.execute_reply.started":"2025-01-09T12:07:44.692457Z","shell.execute_reply":"2025-01-09T12:07:44.692477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating Agents\nproject_planning_agent = Agent(llm=llm,\n  config=agents_config['project_planning_agent']\n)\n\nestimation_agent = Agent(llm=llm,\n  config=agents_config['estimation_agent']\n)\n\nresource_allocation_agent = Agent(llm=llm,\n  config=agents_config['resource_allocation_agent']\n)\n\n# Creating Tasks\ntask_breakdown = Task(\n  config=tasks_config['task_breakdown'],\n  agent=project_planning_agent\n)\n\ntime_resource_estimation = Task(\n  config=tasks_config['time_resource_estimation'],\n  agent=estimation_agent\n)\n\nresource_allocation = Task(\n  config=tasks_config['resource_allocation'],\n  agent=resource_allocation_agent,\n  output_pydantic=ProjectPlan # This is the structured output we want\n)\n\n# Creating Crew\ncrew = Crew(\n  agents=[\n    project_planning_agent,\n    estimation_agent,\n    resource_allocation_agent\n  ],\n  tasks=[\n    task_breakdown,\n    time_resource_estimation,\n    resource_allocation\n  ],\n    \n  verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.694123Z","iopub.status.idle":"2025-01-09T12:07:44.694500Z","shell.execute_reply.started":"2025-01-09T12:07:44.694316Z","shell.execute_reply":"2025-01-09T12:07:44.694334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display, Markdown\n\nproject = 'Website'\nindustry = 'Technology'\nproject_objectives = 'Create a website for a small business'\nteam_members = \"\"\"\n- John Doe (Project Manager)\n- Jane Doe (Software Engineer)\n- Bob Smith (Designer)\n- Alice Johnson (QA Engineer)\n- Tom Brown (QA Engineer)\n\"\"\"\nproject_requirements = \"\"\"\n- Create a responsive design that works well on desktop and mobile devices\n- Implement a modern, visually appealing user interface with a clean look\n- Develop a user-friendly navigation system with intuitive menu structure\n- Include an \"About Us\" page highlighting the company's history and values\n- Design a \"Services\" page showcasing the business's offerings with descriptions\n- Create a \"Contact Us\" page with a form and integrated map for communication\n- Implement a blog section for sharing industry news and company updates\n- Ensure fast loading times and optimize for search engines (SEO)\n- Integrate social media links and sharing capabilities\n- Include a testimonials section to showcase customer feedback and build trust\n\"\"\"\n\n# Format the dictionary as Markdown for a better display in Jupyter Lab\nformatted_output = f\"\"\"\n**Project Type:** {project}\n\n**Project Objectives:** {project_objectives}\n\n**Industry:** {industry}\n\n**Team Members:**\n{team_members}\n**Project Requirements:**\n{project_requirements}\n\"\"\"\n# Display the formatted output as Markdown\ndisplay(Markdown(formatted_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.695562Z","iopub.status.idle":"2025-01-09T12:07:44.696087Z","shell.execute_reply.started":"2025-01-09T12:07:44.695806Z","shell.execute_reply":"2025-01-09T12:07:44.695833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The given Python dictionary\ninputs = {\n  'project_type': project,\n  'project_objectives': project_objectives,\n  'industry': industry,\n  'team_members': team_members,\n  'project_requirements': project_requirements\n}\n\n# Run the crew\nresult = crew.kickoff(\n  inputs=inputs\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.697922Z","iopub.status.idle":"2025-01-09T12:07:44.698436Z","shell.execute_reply.started":"2025-01-09T12:07:44.698214Z","shell.execute_reply":"2025-01-09T12:07:44.698234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## TAVILY search for information in the internet\n\nAI Agents in LangGraph  DeepLearning.ai courses","metadata":{}},{"cell_type":"code","source":"pip install langgraph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.699898Z","iopub.status.idle":"2025-01-09T12:07:44.700301Z","shell.execute_reply.started":"2025-01-09T12:07:44.700110Z","shell.execute_reply":"2025-01-09T12:07:44.700129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install langchain_community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.701499Z","iopub.status.idle":"2025-01-09T12:07:44.701851Z","shell.execute_reply.started":"2025-01-09T12:07:44.701678Z","shell.execute_reply":"2025-01-09T12:07:44.701697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install langchain_huggingface","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.703631Z","iopub.status.idle":"2025-01-09T12:07:44.704027Z","shell.execute_reply.started":"2025-01-09T12:07:44.703824Z","shell.execute_reply":"2025-01-09T12:07:44.703843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langgraph.graph import StateGraph, END\nfrom typing import TypedDict, Annotated\nimport operator\nfrom langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n# from langchain_openai import ChatOpenAI\nfrom langchain_community.tools.tavily_search import TavilySearchResults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.705685Z","iopub.status.idle":"2025-01-09T12:07:44.706111Z","shell.execute_reply.started":"2025-01-09T12:07:44.705882Z","shell.execute_reply":"2025-01-09T12:07:44.705903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ[\"TAVILY_API_KEY\"] = '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'\ntool = TavilySearchResults(max_results=4) #increased number of results\nprint(type(tool))\nprint(tool.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.716297Z","iopub.status.idle":"2025-01-09T12:07:44.716709Z","shell.execute_reply.started":"2025-01-09T12:07:44.716519Z","shell.execute_reply":"2025-01-09T12:07:44.716540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.chat_models.huggingface import ChatHuggingFace\nfrom langchain_community.llms import HuggingFaceEndpoint\nllm=HuggingFaceEndpoint(repo_id='', trust_remote_code=True)\n#'nvidia/Hymba-1.5B-Instruct'\n#google/flan-t5-large -> text2text, not working with that\nmodel=ChatHuggingFace(llm=llm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.718026Z","iopub.status.idle":"2025-01-09T12:07:44.718438Z","shell.execute_reply.started":"2025-01-09T12:07:44.718261Z","shell.execute_reply":"2025-01-09T12:07:44.718280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Start with easy approach_ \nhttps://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/2/build-an-agent-from-scratch","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import InferenceClient\n\nclient=InferenceClient(api_key='hf_********')\n\nclass Agent:\n    def __init__(self, system=\"\"):\n        self.system = system\n        self.messages = []\n        if self.system:\n            self.messages.append({\"role\": \"system\", \"content\": system})\n\n    def __call__(self, message):\n        self.messages.append({\"role\": \"user\", \"content\": message})\n        result = self.execute()\n        self.messages.append({\"role\": \"assistant\", \"content\": result})\n        return result\n\n    def execute(self):\n        inputs = tokenizer.apply_chat_template(self.messages, add_generation_prompt=True, return_tensors=\"pt\")\n        outputs = model.generate(inputs, max_new_tokens=512, do_sample=False)\n        return tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.719782Z","iopub.status.idle":"2025-01-09T12:07:44.720216Z","shell.execute_reply.started":"2025-01-09T12:07:44.719982Z","shell.execute_reply":"2025-01-09T12:07:44.720002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"\"\"\nYou are a nice assistant that answers all questions\n\"\"\".strip()\n\ndef calculate(what):\n    return eval(what)\n\ndef average_dog_weight(name):\n    if name in \"Scottish Terrier\": \n        return(\"Scottish Terriers average 20 lbs\")\n    elif name in \"Border Collie\":\n        return(\"a Border Collies average weight is 37 lbs\")\n    elif name in \"Toy Poodle\":\n        return(\"a toy poodles average weight is 7 lbs\")\n    else:\n        return(\"An average dog weights 50 lbs\")\n\nknown_actions = {\n    \"calculate\": calculate,\n    \"average_dog_weight\": average_dog_weight\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.722404Z","iopub.status.idle":"2025-01-09T12:07:44.722791Z","shell.execute_reply.started":"2025-01-09T12:07:44.722610Z","shell.execute_reply":"2025-01-09T12:07:44.722630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"abot = Agent(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.723737Z","iopub.status.idle":"2025-01-09T12:07:44.724303Z","shell.execute_reply.started":"2025-01-09T12:07:44.723999Z","shell.execute_reply":"2025-01-09T12:07:44.724028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = abot(\"How much does a toy poodle weigh?\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.726448Z","iopub.status.idle":"2025-01-09T12:07:44.726851Z","shell.execute_reply.started":"2025-01-09T12:07:44.726664Z","shell.execute_reply":"2025-01-09T12:07:44.726685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# !! TO SOLVE","metadata":{}},{"cell_type":"code","source":"class AgentState(TypedDict):\n    messages: Annotated[list[AnyMessage], operator.add]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.728085Z","iopub.status.idle":"2025-01-09T12:07:44.728483Z","shell.execute_reply.started":"2025-01-09T12:07:44.728302Z","shell.execute_reply":"2025-01-09T12:07:44.728322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Agent:\n\n    def __init__(self, model, tools, system=\"\"):\n        self.system = system\n        graph = StateGraph(AgentState)\n        graph.add_node(\"llm\", self.call_openai)\n        graph.add_node(\"action\", self.take_action)\n        graph.add_conditional_edges(\n            \"llm\",\n            self.exists_action,\n            {True: \"action\", False: END}\n        )\n        graph.add_edge(\"action\", \"llm\")\n        graph.set_entry_point(\"llm\")\n        self.graph = graph.compile()\n        self.tools = {t.name: t for t in tools}\n        self.model = model.bind_tools(tools)\n\n    def exists_action(self, state: AgentState):\n        result = state['messages'][-1]\n        return len(result.tool_calls) > 0\n\n    def call_openai(self, state: AgentState):\n        messages = state['messages']\n        if self.system:\n            messages = [SystemMessage(content=self.system)] + messages\n        message = self.model.invoke(messages)\n        return {'messages': [message]}\n\n    def take_action(self, state: AgentState):\n        tool_calls = state['messages'][-1].tool_calls\n        results = []\n        for t in tool_calls:\n            print(f\"Calling: {t}\")\n            if not t['name'] in self.tools:      # check for bad tool name from LLM\n                print(\"\\n ....bad tool name....\")\n                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n            else:\n                result = self.tools[t['name']].invoke(t['args'])\n            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n        print(\"Back to the model!\")\n        return {'messages': results}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.731358Z","iopub.status.idle":"2025-01-09T12:07:44.731786Z","shell.execute_reply.started":"2025-01-09T12:07:44.731588Z","shell.execute_reply":"2025-01-09T12:07:44.731609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\nYou are allowed to make multiple calls (either together or in sequence). \\\nOnly look up information when you are sure of what you want. \\\nIf you need to look up some information before asking a follow up question, you are allowed to do that!\n\"\"\"\n\nmodel = model  #reduce inference cost\nabot = Agent(model, [tool], system=prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.733460Z","iopub.status.idle":"2025-01-09T12:07:44.733841Z","shell.execute_reply.started":"2025-01-09T12:07:44.733651Z","shell.execute_reply":"2025-01-09T12:07:44.733671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"messages = [HumanMessage(content=\"What is the weather in sf?\")]\nresult = abot.graph.invoke({\"messages\": messages})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.735638Z","iopub.status.idle":"2025-01-09T12:07:44.736143Z","shell.execute_reply.started":"2025-01-09T12:07:44.735852Z","shell.execute_reply":"2025-01-09T12:07:44.735873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Image-text-to-image","metadata":{}},{"cell_type":"code","source":"pip install diffusers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.737355Z","iopub.status.idle":"2025-01-09T12:07:44.737733Z","shell.execute_reply.started":"2025-01-09T12:07:44.737550Z","shell.execute_reply":"2025-01-09T12:07:44.737569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom diffusers import AutoPipelineForImage2Image\nfrom diffusers.utils import make_image_grid, load_image\n\npipeline = AutoPipelineForImage2Image.from_pretrained(\n    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n)\n\n# this helps us to reduce memory usage- since SDXL is a bit heavy, this could help by\n# offloading the model to CPU w/o hurting performance.\npipeline.enable_model_cpu_offload()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.739029Z","iopub.status.idle":"2025-01-09T12:07:44.739421Z","shell.execute_reply.started":"2025-01-09T12:07:44.739252Z","shell.execute_reply":"2025-01-09T12:07:44.739270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepare image\nurl = \"https://th.bing.com/th/id/R.312295bd88a0e2cf600e0d5f5733d1d9?rik=xEQTj38F2l5%2fsQ&pid=ImgRaw&r=0\"\n\ninit_image = load_image(url)\n\nprompt = \"convert into a disney palette\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, strength=0.5).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.740953Z","iopub.status.idle":"2025-01-09T12:07:44.741434Z","shell.execute_reply.started":"2025-01-09T12:07:44.741241Z","shell.execute_reply":"2025-01-09T12:07:44.741262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepare image\nurl = \"https://www.elllobregat.com/fotos/80/escola_utmar.jpg\"\n\ninit_image = load_image(url)\n\nprompt = \"convert the following image into Simpson palette\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, strength=0.5).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.744765Z","iopub.status.idle":"2025-01-09T12:07:44.745343Z","shell.execute_reply.started":"2025-01-09T12:07:44.745138Z","shell.execute_reply":"2025-01-09T12:07:44.745161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepare image\nurl = \"/kaggle/input/images/mariaandsara.jpg\"\n\ninit_image = load_image(url)\n\nprompt = \"convert the following image into Simpson palette\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, strength=0.5).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.746903Z","iopub.status.idle":"2025-01-09T12:07:44.747296Z","shell.execute_reply.started":"2025-01-09T12:07:44.747112Z","shell.execute_reply":"2025-01-09T12:07:44.747130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"1+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.749252Z","iopub.status.idle":"2025-01-09T12:07:44.749657Z","shell.execute_reply.started":"2025-01-09T12:07:44.749472Z","shell.execute_reply":"2025-01-09T12:07:44.749492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepare image\nurl = \"/kaggle/input/images/mariaandsara.jpg\"\n\ninit_image = load_image(url)\n\nprompt = \"Draw a Picasso style painting\"\n\n# pass prompt and image to pipeline\nimage = pipeline(prompt, image=init_image, strength=0.5).images[0]\nmake_image_grid([init_image, image], rows=1, cols=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T12:07:44.751557Z","iopub.status.idle":"2025-01-09T12:07:44.751909Z","shell.execute_reply.started":"2025-01-09T12:07:44.751738Z","shell.execute_reply":"2025-01-09T12:07:44.751757Z"}},"outputs":[],"execution_count":null}]}